{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datumbox/datumbox-framework  : Cloning repo\n",
      "Repository 'datumbox/datumbox-framework' cloned to path: repos/datumbox/datumbox-framework\n",
      "datumbox/datumbox-framework  : Finished cloning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Switched to branch 'TEMP_LEFT_BRANCH'\n",
      "fatal: not a tree object\n",
      "/snap/core20/current/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.29' not found (required by /lib/x86_64-linux-gnu/libproxy.so.1)\n",
      "Failed to load module: /home/benrr/snap/code/common/.cache/gio-modules/libgiolibproxy.so\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conflicting line:         ClustererValidator.ValidationMetrics vm = instance.validate(validationData);\n",
      "\n",
      "--- File Added in Both Parents ---\n",
      "\n",
      "This file was added in both parents and is not present in the base branch.\n",
      "Conflicting line:         MultinomialDPMM.ValidationMetrics vm = instance.validate(validationData);\n",
      "\n",
      "--- File Added in Both Parents ---\n",
      "\n",
      "This file was added in both parents and is not present in the base branch.\n",
      "\n",
      "--- Rest of Conflicting File ---\n",
      "\n",
      "/**\n",
      " * Copyright (C) 2013-2016 Vasilis Vryniotis <bbriniotis@datumbox.com>\n",
      " *\n",
      " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      " * you may not use this file except in compliance with the License.\n",
      " * You may obtain a copy of the License at\n",
      " *\n",
      " *     http://www.apache.org/licenses/LICENSE-2.0\n",
      " *\n",
      " * Unless required by applicable law or agreed to in writing, software\n",
      " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      " * See the License for the specific language governing permissions and\n",
      " * limitations under the License.\n",
      " */\n",
      "package com.datumbox.framework.core.machinelearning.clustering;\n",
      "\n",
      "import com.datumbox.framework.common.Configuration;\n",
      "import com.datumbox.framework.common.dataobjects.Dataframe;\n",
      "import com.datumbox.framework.core.machinelearning.validators.ClustererValidator;\n",
      "import com.datumbox.framework.tests.Constants;\n",
      "import com.datumbox.framework.tests.Datasets;\n",
      "import com.datumbox.framework.tests.abstracts.AbstractTest;\n",
      "import org.junit.Assert;\n",
      "import org.junit.Test;\n",
      "\n",
      "import java.util.HashMap;\n",
      "import java.util.Map;\n",
      "\n",
      "import static org.junit.Assert.assertEquals;\n",
      "\n",
      "/**\n",
      " * Test cases for MultinomialDPMM.\n",
      " *\n",
      " * @author Vasilis Vryniotis <bbriniotis@datumbox.com>\n",
      " */\n",
      "public class MultinomialDPMMTest extends AbstractTest {\n",
      "    \n",
      "    /**\n",
      "     * Test of validate method, of class MultinomialDPMM.\n",
      "     */\n",
      "    @Test\n",
      "    public void testValidate() {\n",
      "        logger.info(\"validate\"); \n",
      "        \n",
      "        Configuration conf = Configuration.getConfiguration();\n",
      "        \n",
      "        Dataframe[] data = Datasets.multinomialClusters(conf);\n",
      "        \n",
      "        Dataframe trainingData = data[0];\n",
      "        Dataframe validationData = data[1];\n",
      "\n",
      "        \n",
      "        String dbName = this.getClass().getSimpleName();\n",
      "        MultinomialDPMM instance = new MultinomialDPMM(dbName, conf);\n",
      "        \n",
      "        MultinomialDPMM.TrainingParameters param = new MultinomialDPMM.TrainingParameters();\n",
      "        param.setAlpha(0.01);\n",
      "        param.setMaxIterations(100);\n",
      "        param.setInitializationMethod(MultinomialDPMM.TrainingParameters.Initialization.ONE_CLUSTER_PER_RECORD);\n",
      "        param.setAlphaWords(1);\n",
      "        \n",
      "        instance.fit(trainingData, param);\n",
      "        \n",
      "        instance.close();\n",
      "        //instance = null;\n",
      "        instance = new MultinomialDPMM(dbName, conf);\n",
      "\n",
      "<<<<<<< HEAD\n",
      "        ClustererValidator.ValidationMetrics vm = instance.validate(validationData);\n",
      "=======\n",
      "        MultinomialDPMM.ValidationMetrics vm = instance.validate(validationData);\n",
      ">>>>>>> TEMP_RIGHT_BRANCH\n",
      "\n",
      "        double expResult = 1.0;\n",
      "        double result = vm.getPurity();\n",
      "        assertEquals(expResult, result, Constants.DOUBLE_ACCURACY_HIGH);\n",
      "        \n",
      "        instance.delete();\n",
      "        \n",
      "        trainingData.delete();\n",
      "        validationData.delete();\n",
      "    }\n",
      "\n",
      "    \n",
      "    /**\n",
      "     * Test of kFoldCrossValidation method, of class MultinomialDPMM.\n",
      "     */\n",
      "    @Test\n",
      "    public void testKFoldCrossValidation() {\n",
      "        logger.info(\"kFoldCrossValidation\");\n",
      "        \n",
      "        Configuration conf = Configuration.getConfiguration();\n",
      "        \n",
      "        int k = 5;\n",
      "        \n",
      "        Dataframe[] data = Datasets.multinomialClusters(conf);\n",
      "        Dataframe trainingData = data[0];\n",
      "        data[1].delete();\n",
      "        \n",
      "        \n",
      "        String dbName = this.getClass().getSimpleName();\n",
      "        MultinomialDPMM instance = new MultinomialDPMM(dbName, conf);\n",
      "        \n",
      "        MultinomialDPMM.TrainingParameters param = new MultinomialDPMM.TrainingParameters();\n",
      "        param.setAlpha(0.01);\n",
      "        param.setMaxIterations(100);\n",
      "        param.setInitializationMethod(MultinomialDPMM.TrainingParameters.Initialization.ONE_CLUSTER_PER_RECORD);\n",
      "        param.setAlphaWords(1);\n",
      "\n",
      "        ClustererValidator.ValidationMetrics vm = instance.kFoldCrossValidation(trainingData, param, k);\n",
      "\n",
      "        \n",
      "        double expResult = 1.0;\n",
      "        double result = vm.getPurity();\n",
      "        Assert.assertEquals(expResult, result, Constants.DOUBLE_ACCURACY_HIGH);\n",
      "        instance.delete();\n",
      "        \n",
      "        trainingData.delete();\n",
      "    }\n",
      "\n",
      "    \n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('../../results/result.csv')\n",
    "\n",
    "repo_num = 1084\n",
    "# merge_tool = \"gitmerge-recursive-patience\"\n",
    "# merge_tool = \"spork\"\n",
    "# merge_tool = \"gitmerge-recursive-minimal\"\n",
    "# merge_tool = \"gitmerge-resrepo_num = 3595\n",
    "# merge_tool = \"gitmerge-recursive-patience\"\n",
    "# merge_tool = \"spork\"\n",
    "# merge_tool = \"git merge-resolve\"\n",
    "# merge_tool = \"intellimerge\"\n",
    "merge_tool = 'gitmerge-ort-ignorespace'\n",
    "# merge_tool = 'gitmerge-ort'\n",
    "\n",
    "repo_name = df.iloc[repo_num][\"repo_name\"]\n",
    "\n",
    "script = \"../scripts/merge_tools/\" + merge_tool + \".sh\"\n",
    "from merge_tester import MERGE_STATE\n",
    "df[merge_tool].apply(lambda x: MERGE_STATE[x])[0]\n",
    "from validate_repos import clone_repo\n",
    "repo = clone_repo(repo_name) # Return a Git-Python repo object\n",
    "repo.remote().fetch()\n",
    "repo.git.checkout(df.iloc[repo_num][\"left\"], force=True)\n",
    "repo.submodule_update()\n",
    "repo.git.checkout(\"-b\", \"TEMP_LEFT_BRANCH\", force=True)\n",
    "repo.git.checkout(df.iloc[repo_num][\"right\"], force=True)\n",
    "repo.submodule_update()\n",
    "repo.git.checkout(\"-b\", \"TEMP_RIGHT_BRANCH\", force=True)\n",
    "repo_path = repo.git.rev_parse(\"--show-toplevel\")\n",
    "\n",
    "import subprocess\n",
    "import re\n",
    "import os\n",
    "result = subprocess.run([script, repo_path, \"TEMP_LEFT_BRANCH\", \"TEMP_RIGHT_BRANCH\"], stdout=subprocess.PIPE, text=True)\n",
    "conflict_file_match = re.search(r'CONFLICT \\(.+\\): Merge conflict in (.+)', result.stdout)\n",
    "conflicting_lines = []\n",
    "\n",
    "if conflict_file_match:\n",
    "    conflicting_file = conflict_file_match.group(1)\n",
    "    full_path = os.path.join(repo_path, conflicting_file)\n",
    "\n",
    "    # Open the conflicting file and print the base branch content for the conflicting lines\n",
    "    with open(full_path, 'r') as file:\n",
    "        file_content = file.read()\n",
    "\n",
    "        # Split the conflicting file content into lines\n",
    "        lines = file_content.split('\\n')\n",
    "\n",
    "        # Flag to indicate whether the current line is within a conflict marker\n",
    "        in_conflict = False\n",
    "        conflict_offset = -1\n",
    "\n",
    "        df[merge_tool].apply(lambda x: MERGE_STATE[x])[0]\n",
    "        from validate_repos import clone_repo2\n",
    "        repo = clone_repo2(repo_name) # Return a Git-Python repo object\n",
    "        repo.remote().fetch()\n",
    "        repo.git.checkout(df.iloc[repo_num][\"base\"], force=True)\n",
    "        repo.submodule_update()\n",
    "\n",
    "        file_path2 = os.path.join('/home/benrr/miniconda3/envs/merge_1/AST-Merging-Evaluation/src/python/repos2', repo_name, conflicting_file)\n",
    "\n",
    "        # Iterate through the lines and print the base branch content for conflicting lines\n",
    "        base_lines = [\">>>>>> BASE\"]\n",
    "        i = 0\n",
    "        while (i < len(lines)):\n",
    "            line = lines[i]\n",
    "            if line.startswith(\"<<<<<<<\"):\n",
    "                conflict_offset += 1\n",
    "                in_conflict = True\n",
    "            elif line.startswith(\">>>>>>>\"):\n",
    "                for j, line3 in enumerate(base_lines):\n",
    "                    lines.insert(i + j + 1, line3)\n",
    "                i += len(base_lines)\n",
    "                conflict_offset += 2\n",
    "            elif line.startswith(\"=======\"):\n",
    "                in_conflict = False\n",
    "            elif in_conflict:\n",
    "                line_number = i - conflict_offset\n",
    "                conflicting_lines.append(i - conflict_offset)\n",
    "                try:\n",
    "                    with open(file_path2, 'r') as file:\n",
    "                        lines2 = file.readlines()\n",
    "                        if 1 <= line_number <= len(lines2):\n",
    "                            desired_line = lines2[line_number - 1]\n",
    "                            base_lines.insert(0, desired_line)\n",
    "                            print(f\"Base {line_number}: {desired_line}\")\n",
    "                        else:\n",
    "                            print(f\"Error: Line number {line_number} is out of range for the file.\")\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"Error: File '{file_path2}' not found.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred: {e}\")\n",
    "            i += 1\n",
    "\n",
    "    with open(full_path, 'w') as file:\n",
    "        file.write('\\n'.join(lines))\n",
    "\n",
    "    # Open the conflicting file with the default text editor\n",
    "    subprocess.run([\"xdg-open\", full_path], check=True)\n",
    "else:\n",
    "    print(\"No conflicting file found in the output.\")\n",
    "\n",
    "print(conflicting_lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
