idx,branch_name,merge,left,right,notes,num_diff_files,num_diff_lines,imports_involved,non_java_involved,diff contains java file,diff_logs,left_tree_fingerprint,left parent test result,right_tree_fingerprint,right parent test result,parents pass,test merge,sampled for testing
11,refs/heads/master,1a1277596eeedf1811d9da68de9e0bafb92059a9,05e7b42255f0c17afe1a5e8e49b2ec5b07c15e65,993aae7a7223674b0f86ecaf430deea7be88ecf5,,5,54,False,True,False,"{'base_left': 'cache/diff_analyzer/logs/librato/metrics-librato/05e7b42255f0c17afe1a5e8e49b2ec5b07c15e65_993aae7a7223674b0f86ecaf430deea7be88ecf5_base_left.log', 'base_right': 'cache/diff_analyzer/logs/librato/metrics-librato/05e7b42255f0c17afe1a5e8e49b2ec5b07c15e65_993aae7a7223674b0f86ecaf430deea7be88ecf5_base_right.log', 'left_right': 'cache/diff_analyzer/logs/librato/metrics-librato/05e7b42255f0c17afe1a5e8e49b2ec5b07c15e65_993aae7a7223674b0f86ecaf430deea7be88ecf5_left_right.log'}",,,,,,False,False
12,refs/heads/master,05e7b42255f0c17afe1a5e8e49b2ec5b07c15e65,77f1c331a3059c7676f2c9d0196add80cddb38bf,e26812d176fe1e8ffbf7313e4552b3b754e1f762,,4,21,False,True,False,"{'base_left': 'cache/diff_analyzer/logs/librato/metrics-librato/77f1c331a3059c7676f2c9d0196add80cddb38bf_e26812d176fe1e8ffbf7313e4552b3b754e1f762_base_left.log', 'base_right': 'cache/diff_analyzer/logs/librato/metrics-librato/77f1c331a3059c7676f2c9d0196add80cddb38bf_e26812d176fe1e8ffbf7313e4552b3b754e1f762_base_right.log', 'left_right': 'cache/diff_analyzer/logs/librato/metrics-librato/77f1c331a3059c7676f2c9d0196add80cddb38bf_e26812d176fe1e8ffbf7313e4552b3b754e1f762_left_right.log'}",,,,,,False,False
14,refs/heads/master,0720f6dce4f8da338bbfcfa9e2c0009de7772709,a0891f0785d08d8abaaf3dc84009bd8769d4ca8a,5afe7a103adde58eab777f26fcc616f06601207d,,6,134,True,True,True,"{'base_left': 'cache/diff_analyzer/logs/librato/metrics-librato/a0891f0785d08d8abaaf3dc84009bd8769d4ca8a_5afe7a103adde58eab777f26fcc616f06601207d_base_left.log', 'base_right': 'cache/diff_analyzer/logs/librato/metrics-librato/a0891f0785d08d8abaaf3dc84009bd8769d4ca8a_5afe7a103adde58eab777f26fcc616f06601207d_base_right.log', 'left_right': 'cache/diff_analyzer/logs/librato/metrics-librato/a0891f0785d08d8abaaf3dc84009bd8769d4ca8a_5afe7a103adde58eab777f26fcc616f06601207d_left_right.log'}",8bfc3fd9e58392e008801f2a7ecac6df5095545d1b829d0d16b0c289206194a4,Tests_passed,8e27d6b8f17a98c1b5d2dc4ea8e66e06e99ffd05081dcd909ca669c52d342b37,Tests_passed,True,True,True
27,refs/heads/master,19aec6c41506cb6e9d761a3763297573536dbcfe,186866ef14704d10766e47f0ba4bd9cd55c3d0df,80ef1a69489f646d4253f8fef914ca000788c8ce,,9,288,True,True,False,"{'base_left': 'cache/diff_analyzer/logs/librato/metrics-librato/186866ef14704d10766e47f0ba4bd9cd55c3d0df_80ef1a69489f646d4253f8fef914ca000788c8ce_base_left.log', 'base_right': 'cache/diff_analyzer/logs/librato/metrics-librato/186866ef14704d10766e47f0ba4bd9cd55c3d0df_80ef1a69489f646d4253f8fef914ca000788c8ce_base_right.log', 'left_right': 'cache/diff_analyzer/logs/librato/metrics-librato/186866ef14704d10766e47f0ba4bd9cd55c3d0df_80ef1a69489f646d4253f8fef914ca000788c8ce_left_right.log'}",,,,,,False,False
28,refs/heads/master,80ef1a69489f646d4253f8fef914ca000788c8ce,cc744d38b4a21b966cd4117520f4b6d08553adb7,82e734385478ae6815f96920708905c176fa7727,,9,289,True,True,False,"{'base_left': 'cache/diff_analyzer/logs/librato/metrics-librato/cc744d38b4a21b966cd4117520f4b6d08553adb7_82e734385478ae6815f96920708905c176fa7727_base_left.log', 'base_right': 'cache/diff_analyzer/logs/librato/metrics-librato/cc744d38b4a21b966cd4117520f4b6d08553adb7_82e734385478ae6815f96920708905c176fa7727_base_right.log', 'left_right': 'cache/diff_analyzer/logs/librato/metrics-librato/cc744d38b4a21b966cd4117520f4b6d08553adb7_82e734385478ae6815f96920708905c176fa7727_left_right.log'}",,,,,,False,False
29,refs/heads/master,186866ef14704d10766e47f0ba4bd9cd55c3d0df,f3ebac2366d53b3e82b9dad98d2f2fe956c41b48,82e734385478ae6815f96920708905c176fa7727,,2,7,False,True,False,"{'base_left': 'cache/diff_analyzer/logs/librato/metrics-librato/f3ebac2366d53b3e82b9dad98d2f2fe956c41b48_82e734385478ae6815f96920708905c176fa7727_base_left.log', 'base_right': 'cache/diff_analyzer/logs/librato/metrics-librato/f3ebac2366d53b3e82b9dad98d2f2fe956c41b48_82e734385478ae6815f96920708905c176fa7727_base_right.log', 'left_right': 'cache/diff_analyzer/logs/librato/metrics-librato/f3ebac2366d53b3e82b9dad98d2f2fe956c41b48_82e734385478ae6815f96920708905c176fa7727_left_right.log'}",,,,,,False,False
30,refs/heads/master,140caf9da468df3c5bedacf427b06903b0933a9e,0fe7e8d986428c910b046bec995e793e44aed48f,f5efb2b25af84d04977b3ceca7712dabe4a4da61,,13,331,True,True,True,"{'base_left': 'cache/diff_analyzer/logs/librato/metrics-librato/0fe7e8d986428c910b046bec995e793e44aed48f_f5efb2b25af84d04977b3ceca7712dabe4a4da61_base_left.log', 'base_right': 'cache/diff_analyzer/logs/librato/metrics-librato/0fe7e8d986428c910b046bec995e793e44aed48f_f5efb2b25af84d04977b3ceca7712dabe4a4da61_base_right.log', 'left_right': 'cache/diff_analyzer/logs/librato/metrics-librato/0fe7e8d986428c910b046bec995e793e44aed48f_f5efb2b25af84d04977b3ceca7712dabe4a4da61_left_right.log'}",cb129afc0ca37612e2333f0638ab9157c2a3ff0dde3a285612c142506186eecd,Tests_passed,6d5abf7af2bc92f56a604fa6e2903a2a481460e39d60c344014aaa3f77022fbb,Tests_passed,True,True,True
31,refs/heads/master,0fe7e8d986428c910b046bec995e793e44aed48f,f20cd00614275ef975d77648e1ff541e04832b51,34d97f335710c209bc71bb0e839c23b279b65d48,,12,229,True,True,True,"{'base_left': 'cache/diff_analyzer/logs/librato/metrics-librato/f20cd00614275ef975d77648e1ff541e04832b51_34d97f335710c209bc71bb0e839c23b279b65d48_base_left.log', 'base_right': 'cache/diff_analyzer/logs/librato/metrics-librato/f20cd00614275ef975d77648e1ff541e04832b51_34d97f335710c209bc71bb0e839c23b279b65d48_base_right.log', 'left_right': 'cache/diff_analyzer/logs/librato/metrics-librato/f20cd00614275ef975d77648e1ff541e04832b51_34d97f335710c209bc71bb0e839c23b279b65d48_left_right.log'}",e37c8a3a9ebb7fa3f3994ae6a55abbe971ce145454a3eee055201081cd2dce72,Tests_passed,29112055e54e5b5c67434eeb00541c2a22e40d5df90b3df73d6589b40c3e1dac,Tests_passed,True,True,True
35,refs/heads/master,677bd40a7f4929f12e86e72639855eb1bb03e953,956520e81ae22d0b02168b9aac57a12c03ad68cd,5dcc965f96a2e6284d9668847865d680525861c7,,3,9,True,True,False,"{'base_left': 'cache/diff_analyzer/logs/librato/metrics-librato/956520e81ae22d0b02168b9aac57a12c03ad68cd_5dcc965f96a2e6284d9668847865d680525861c7_base_left.log', 'base_right': 'cache/diff_analyzer/logs/librato/metrics-librato/956520e81ae22d0b02168b9aac57a12c03ad68cd_5dcc965f96a2e6284d9668847865d680525861c7_base_right.log', 'left_right': 'cache/diff_analyzer/logs/librato/metrics-librato/956520e81ae22d0b02168b9aac57a12c03ad68cd_5dcc965f96a2e6284d9668847865d680525861c7_left_right.log'}",,,,,,False,False
